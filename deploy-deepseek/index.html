<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="robots" content="index, follow">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="baidu-site-verification" content="codeva-tiWIr8OvPt">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.pw0n.xyz","root":"/","scheme":"Pisces","version":"7.8.0","sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":true,"lazyload":false,"pangu":true,"comments":{"style":"gitalk","active":null,"storage":true,"lazyload":false},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="使用 Ollama 轻松部署 DeepSeek-R1 系列模型：Windows, Linux, macOS, Android 全平台指南DeepSeek-R1 系列模型以其卓越的性能和开源特性，吸引了众多开发者的关注。Ollama 作为一个轻量级的模型运行平台，使得部署和使用这些模型变得异常简单。本文将详细介绍如何在 Windows, Linux, macOS 以及 Android 平台上使用 O">
<meta property="og:type" content="article">
<meta property="og:title" content="Windows、Mac、Linux本地部署deepseek教程">
<meta property="og:url" content="https://www.pw0n.xyz/deploy-deepseek/index.html">
<meta property="og:site_name" content="PW0N&#39;s Blog">
<meta property="og:description" content="使用 Ollama 轻松部署 DeepSeek-R1 系列模型：Windows, Linux, macOS, Android 全平台指南DeepSeek-R1 系列模型以其卓越的性能和开源特性，吸引了众多开发者的关注。Ollama 作为一个轻量级的模型运行平台，使得部署和使用这些模型变得异常简单。本文将详细介绍如何在 Windows, Linux, macOS 以及 Android 平台上使用 O">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-02-14T10:29:21.000Z">
<meta property="article:modified_time" content="2025-02-25T08:52:41.496Z">
<meta property="article:author" content="PW0N">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="Deepseek">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Windows">
<meta property="article:tag" content="Mac">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.pw0n.xyz/deploy-deepseek/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/ilyabirman-likely@2/release/likely.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><style>
#needsharebutton-postbottom {
  cursor: pointer;
  height: 26px;
  margin-top: 10px;
  position: relative;
}
#needsharebutton-postbottom .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 3px;
  display: initial;
  padding: 1px 4px;
}
</style>
  <title>Windows、Mac、Linux本地部署deepseek教程 | PW0N's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4839637409222286"
     crossorigin="anonymous"></script>
<link rel="alternate" href="/atom.xml" title="PW0N's Blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="stylesheet" href="/css/prism.css" type="text/css"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">PW0N's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">分享更多的技术让志同道合的一起学习交流</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-nav">

    <a href="/nav/" rel="section"><i class="fa fa-compass fa-fw"></i>导航</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-language">

    <a href="https://en.pw0n.xyz/" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-language fa-fw"></i>English</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.pw0n.xyz/deploy-deepseek/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="PW0N">
      <meta itemprop="description" content="阅读我对网络技术的深入分析和最新趋势的见解，同时了解我个人的生活记录和经验分享。
无论是技术教程还是生活故事，都能在这里找到有趣的内容。
">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW0N's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Windows、Mac、Linux本地部署deepseek教程
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-14 10:29:21" itemprop="dateCreated datePublished" datetime="2025-02-14T10:29:21+00:00">2025-02-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-02-25 08:52:41" itemprop="dateModified" datetime="2025-02-25T08:52:41+00:00">2025-02-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deepseek/" itemprop="url" rel="index"><span itemprop="name">Deepseek</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="使用-Ollama-轻松部署-DeepSeek-R1-系列模型：Windows-Linux-macOS-Android-全平台指南"><a href="#使用-Ollama-轻松部署-DeepSeek-R1-系列模型：Windows-Linux-macOS-Android-全平台指南" class="headerlink" title="使用 Ollama 轻松部署 DeepSeek-R1 系列模型：Windows, Linux, macOS, Android 全平台指南"></a>使用 Ollama 轻松部署 DeepSeek-R1 系列模型：Windows, Linux, macOS, Android 全平台指南</h1><p>DeepSeek-R1 系列模型以其卓越的性能和开源特性，吸引了众多开发者的关注。Ollama 作为一个轻量级的模型运行平台，使得部署和使用这些模型变得异常简单。本文将详细介绍如何在 Windows, Linux, macOS 以及 Android 平台上使用 Ollama 部署 DeepSeek-R1 系列模型，包括 DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, DeepSeek-R1-Distill-Llama-8B, DeepSeek-R1-Distill-Qwen-14B, DeepSeek-R1-Distill-Qwen-32B 和 DeepSeek-R1-Distill-Llama-70B。 针对低配置设备，我们也会重点介绍部署 DeepSeek-R1-Distill-Qwen-1.5B 模型。</p>
<p><strong>为什么选择 Ollama？</strong></p>
<ul>
<li>简单易用: Ollama 简化了模型下载、安装和运行的复杂过程。</li>
<li>跨平台支持: Ollama 支持 Windows, Linux, macOS 和 Android 平台。</li>
<li>轻量级: Ollama 资源占用低，即使在配置较低的设备上也能流畅运行。</li>
<li>社区驱动: Ollama 拥有活跃的社区，提供丰富的模型和技术支持。</li>
</ul>
<p><strong>准备工作</strong></p>
<p>在开始之前，请确保满足以下条件：</p>
<ul>
<li>硬件要求: 根据所选模型的规模，需要足够的内存和磁盘空间。DeepSeek-R1-Distill-Qwen-1.5B 模型对硬件要求较低，适合低配置设备。</li>
<li>Ollama 安装包: 从 Ollama 官网下载对应平台的安装包： <a target="_blank" rel="noopener external nofollow noreferrer" href="https://ollama.com/">https://ollama.com/</a></li>
</ul>
<h2 id="第一部分：Ollama-安装"><a href="#第一部分：Ollama-安装" class="headerlink" title="第一部分：Ollama 安装"></a>第一部分：Ollama 安装</h2><h3 id="1-Windows-平台"><a href="#1-Windows-平台" class="headerlink" title="1. Windows 平台"></a>1. Windows 平台</h3><ul>
<li>下载 Windows 版本的 Ollama 安装包 (<code>.exe</code> 文件)。</li>
<li>双击安装包，按照提示完成安装。</li>
<li>安装完成后，在命令提示符或 PowerShell 中输入 <code>ollama --version</code> 验证安装是否成功。</li>
</ul>
<h3 id="2-Linux-平台"><a href="#2-Linux-平台" class="headerlink" title="2. Linux 平台"></a>2. Linux 平台</h3><ul>
<li><p>根据您的 Linux 发行版，使用以下命令安装 Ollama：</p>
<ul>
<li><strong>Debian/Ubuntu:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>其他 Linux 发行版:</strong> 访问 Ollama 官网获取详细的安装指南。</li>
</ul>
</li>
<li><p>安装完成后，在终端中输入 <code>ollama --version</code> 验证安装是否成功。</p>
</li>
</ul>
<h3 id="3-macOS-平台"><a href="#3-macOS-平台" class="headerlink" title="3. macOS 平台"></a>3. macOS 平台</h3><ul>
<li>下载 macOS 版本的 Ollama 安装包 (<code>.dmg</code> 文件)。</li>
<li>双击安装包，将 Ollama 拖拽到 “Applications” 文件夹。</li>
<li>打开终端，输入 <code>ollama --version</code> 验证安装是否成功。</li>
</ul>
<h3 id="4-Android-平台-通过-Termux"><a href="#4-Android-平台-通过-Termux" class="headerlink" title="4. Android 平台 (通过 Termux)**"></a>4. Android 平台 (通过 Termux)**</h3><p>Android 上的 Ollama 安装稍微复杂一些，需要借助 Termux 这个终端模拟器。</p>
<ul>
<li><p><strong>安装 Termux:</strong> 在 Google Play 商店搜索并安装 Termux。</p>
</li>
<li><p><strong>安装必要的软件包:</strong> 打开 Termux，运行以下命令：</p>
<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pkg update</span><br><span class="line">pkg upgrade</span><br><span class="line">pkg install wget curl proot-distro</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><strong>安装 Ubuntu (或其他 Linux 发行版):</strong> 使用 <code>proot-distro</code> 安装一个 Linux 发行版，比如 Ubuntu:</p>
<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proot-distro install ubuntu</span><br></pre></td></tr></tbody></table></figure></li>
<li><p><strong>进入 Ubuntu 环境:</strong></p>
<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proot-distro login ubuntu</span><br></pre></td></tr></tbody></table></figure></li>
<li><p><strong>在 Ubuntu 环境中安装 Ollama:</strong></p>
<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></tbody></table></figure></li>
<li><p><strong>运行 Ollama:</strong> 在 Ubuntu 环境中，使用 <code>ollama --version</code> 验证安装。</p>
</li>
</ul>
<h2 id="第二部分：部署-DeepSeek-R1-模型"><a href="#第二部分：部署-DeepSeek-R1-模型" class="headerlink" title="第二部分：部署 DeepSeek-R1 模型"></a>第二部分：部署 DeepSeek-R1 模型</h2><table>
<thead>
<tr>
<th>模型名称</th>
<th>硬件要求 (最低)</th>
<th>硬件要求 (推荐)</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>DeepSeek-R1-Distill-Qwen-1.5B</strong></td>
<td>CPU (4核), 4GB 内存</td>
<td>CPU (4核), 8GB 内存</td>
<td>低资源设备，快速原型开发，教育学习，简单文本生成/问答</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-Distill-Qwen-7B</strong></td>
<td>GPU (RTX 3060), 16GB 显存, 16GB 内存</td>
<td>GPU (RTX 3060), 24GB 显存, 32GB 内存</td>
<td>中等配置设备，通用文本生成，代码生成，较复杂问答</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-Distill-Llama-8B</strong></td>
<td>GPU (RTX 3060), 16GB 显存, 16GB 内存</td>
<td>GPU (RTX 3060), 24GB 显存, 32GB 内存</td>
<td>对 Llama 架构有偏好，特定数据集微调，文本摘要/信息提取</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-Distill-Qwen-14B</strong></td>
<td>GPU (RTX 3090), 24GB 显存, 32GB 内存</td>
<td>GPU (RTX 3090), 48GB 显存, 64GB 内存</td>
<td>高性能设备，复杂创意写作，高级代码生成，多轮对话系统</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-Distill-Qwen-32B</strong></td>
<td>GPU (A100), 48GB 显存, 64GB 内存</td>
<td>GPU (A100), 80GB 显存, 128GB 内存</td>
<td>顶级硬件设备，高度逼真文本生成，复杂推理/逻辑，科研学术</td>
</tr>
<tr>
<td><strong>DeepSeek-R1-Distill-Llama-70B</strong></td>
<td>多个 GPU (A100), 80GB 显存 (每个 GPU), 128GB 内存</td>
<td>多个 GPU (A100), 80GB 显存 (每个 GPU), 256GB 内存</td>
<td>极致性能需求，超长文本生成/复杂推理，前沿研究</td>
</tr>
</tbody></table>
<p><strong>表格使用说明:</strong></p>
<ul>
<li>模型名称: DeepSeek-R1 系列不同规模的模型名称。</li>
<li>硬件要求 (最低): 运行模型所需的最低硬件配置。 如果低于这个配置，模型可能无法运行或性能严重下降。</li>
<li>硬件要求 (推荐): 获得较好性能体验的推荐硬件配置。 在这个配置下，模型可以更流畅地运行，并获得更好的生成质量。</li>
<li>适用场景: 模型最适合的应用场景。</li>
</ul>
<p>Ollama 简化了模型的部署过程，只需要一个简单的命令即可完成。</p>
<h3 id="1-Windows-Linux-macOS-平台"><a href="#1-Windows-Linux-macOS-平台" class="headerlink" title="1. Windows, Linux, macOS 平台"></a>1. Windows, Linux, macOS 平台</h3><p>打开终端或命令提示符，运行以下命令下载并运行对应的 DeepSeek-R1 模型：</p>
<ul>
<li><strong>DeepSeek-R1-Distill-Qwen-1.5B (适合低配置设备):</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:1.5b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Qwen-7B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:7b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Llama-8B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:8b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Qwen-14B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:14b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Qwen-32B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:32b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Llama-70B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:70b</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<p>Ollama 会自动下载模型文件，并启动一个交互式会话。您可以直接在终端中与模型进行对话。</p>
<h3 id="2-Android-平台-Termux"><a href="#2-Android-平台-Termux" class="headerlink" title="2. Android 平台 (Termux)**"></a>2. Android 平台 (Termux)**</h3><p>在 Termux 中的 Ubuntu 环境下，运行与上述相同的命令即可：</p>
<ul>
<li><strong>DeepSeek-R1-Distill-Qwen-1.5B (适合低配置设备):</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:1.5b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Qwen-7B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:7b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Llama-8B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:8b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Qwen-14B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:14b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Qwen-32B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:32b</span><br></pre></td></tr></tbody></table></figure></li>
<li><strong>DeepSeek-R1-Distill-Llama-70B:</strong><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ollama run deepseek-r1:70b</span><br></pre></td></tr></tbody></table></figure></li>
</ul>
<h2 id="第三部分：使用-DeepSeek-R1-模型"><a href="#第三部分：使用-DeepSeek-R1-模型" class="headerlink" title="第三部分：使用 DeepSeek-R1 模型"></a>第三部分：使用 DeepSeek-R1 模型</h2><p>模型下载完成后，Ollama 会启动一个交互式会话。您可以直接在终端中与模型进行对话。</p>
<p>例如，运行 <code>ollama run deepseek-r1:1.5b</code> 后，您会看到类似以下的提示：</p>
<figure class="highlight python-repl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;&gt;&gt;</span></span><br></pre></td></tr></tbody></table></figure>

<p>现在，您可以输入您的问题或指令，然后按 Enter 键发送给模型。 模型会生成相应的回复。</p>
<p><strong>示例：</strong></p>
<figure class="highlight python-repl"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;&gt;&gt;</span> <span class="language-python">你好，你是谁？</span></span><br><span class="line">我是DeepSeek-R1-Distill-Qwen-1.5B，一个由DeepSeek公司开发的大型语言模型。</span><br></pre></td></tr></tbody></table></figure>

<p><strong>使用提示：</strong></p>
<ul>
<li>清晰明确的指令: 为了获得更好的结果，请使用清晰明确的指令。</li>
<li>上下文信息: 在对话中提供足够的上下文信息，有助于模型理解您的意图。</li>
<li>迭代优化: 根据模型的回复，不断调整您的指令，以获得更满意的结果。</li>
</ul>
<h2 id="第四部分：针对低配置设备的优化-DeepSeek-R1-Distill-Qwen-1-5B"><a href="#第四部分：针对低配置设备的优化-DeepSeek-R1-Distill-Qwen-1-5B" class="headerlink" title="第四部分：针对低配置设备的优化 (DeepSeek-R1-Distill-Qwen-1.5B)"></a>第四部分：针对低配置设备的优化 (DeepSeek-R1-Distill-Qwen-1.5B)</h2><p>如果您的设备配置较低，建议使用 <code>deepseek-r1:1.5b</code> 模型。 此外，还可以尝试以下优化措施：</p>
<ul>
<li>限制模型的内存使用: 可以通过 Ollama 的环境变量来限制模型的内存使用。 具体方法请参考 Ollama 的官方文档。</li>
<li>关闭不必要的后台程序: 关闭不必要的后台程序，释放更多的系统资源给 Ollama。</li>
<li>选择合适的量化版本: Ollama 支持不同量化版本的模型。选择较低的量化版本可以降低内存占用和提高运行速度，但可能会牺牲一定的精度。</li>
</ul>
<h2 id="第五部分：常见问题解答"><a href="#第五部分：常见问题解答" class="headerlink" title="第五部分：常见问题解答"></a>第五部分：常见问题解答</h2><ul>
<li>模型下载速度慢: 模型文件较大，下载速度可能较慢。请确保网络连接稳定，或者尝试使用代理。</li>
<li>Ollama 运行出错: 查看 Ollama 的日志文件，了解错误信息。 常见错误包括内存不足、端口冲突等。</li>
<li>模型回复不准确: 大型语言模型可能会出现幻觉，生成不准确或不符合事实的回复。 请谨慎对待模型的回复，并进行验证。</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文详细介绍了如何在 Windows, Linux, macOS 和 Android 平台上使用 Ollama 部署 DeepSeek-R1 系列模型。 无论您是开发者还是 AI 爱好者，都可以通过 Ollama 轻松体验 DeepSeek-R1 模型的强大功能。 针对低配置设备，DeepSeek-R1-Distill-Qwen-1.5B 模型是一个不错的选择。 希望本文能够帮助您顺利部署和使用 DeepSeek-R1 模型！</p>

    </div>

    
    
    <div class="post-widgets">
    <div class="likely">
        <div class="twitter">Tweet</div>
        <div class="facebook">Share</div>
        <div class="linkedin">Link</div>
        <div class="gplus">Plus</div>
        <div class="vkontakte">Share</div>
        <div class="odnoklassniki">Class</div>
        <div class="telegram">Send</div>
        <div class="whatsapp">Send</div>
        <div class="pinterest">Pin</div>
    </div>
  </div>
  <script src="//cdn.jsdelivr.net/npm/ilyabirman-likely@2/release/likely.min.js"></script><div class="post-widgets">
      <div id="needsharebutton-postbottom">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    </div>

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Linux/" rel="tag"># Linux</a>
              <a href="/tags/Deepseek/" rel="tag"># Deepseek</a>
              <a href="/tags/AI/" rel="tag"># AI</a>
              <a href="/tags/Windows/" rel="tag"># Windows</a>
              <a href="/tags/Mac/" rel="tag"># Mac</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/make-deepseek/" rel="prev" title="我独自一人用Java写了一款AI，对系统和显卡要求极低，代码已开源，效果媲美DeepSeek">
      <i class="fa fa-chevron-left"></i> 我独自一人用Java写了一款AI，对系统和显卡要求极低，代码已开源，效果媲美DeepSeek
    </a></div>
      <div class="post-nav-item">
    <a href="/hk-bank/" rel="next" title="内地小白香港办卡指南：汇丰与中银实战攻略">
      内地小白香港办卡指南：汇丰与中银实战攻略 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>

  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-Ollama-%E8%BD%BB%E6%9D%BE%E9%83%A8%E7%BD%B2-DeepSeek-R1-%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%EF%BC%9AWindows-Linux-macOS-Android-%E5%85%A8%E5%B9%B3%E5%8F%B0%E6%8C%87%E5%8D%97"><span class="nav-number">1.</span> <span class="nav-text">使用 Ollama 轻松部署 DeepSeek-R1 系列模型：Windows, Linux, macOS, Android 全平台指南</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9AOllama-%E5%AE%89%E8%A3%85"><span class="nav-number">1.1.</span> <span class="nav-text">第一部分：Ollama 安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Windows-%E5%B9%B3%E5%8F%B0"><span class="nav-number">1.1.1.</span> <span class="nav-text">1. Windows 平台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Linux-%E5%B9%B3%E5%8F%B0"><span class="nav-number">1.1.2.</span> <span class="nav-text">2. Linux 平台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-macOS-%E5%B9%B3%E5%8F%B0"><span class="nav-number">1.1.3.</span> <span class="nav-text">3. macOS 平台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Android-%E5%B9%B3%E5%8F%B0-%E9%80%9A%E8%BF%87-Termux"><span class="nav-number">1.1.4.</span> <span class="nav-text">4. Android 平台 (通过 Termux)**</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E9%83%A8%E7%BD%B2-DeepSeek-R1-%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.</span> <span class="nav-text">第二部分：部署 DeepSeek-R1 模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Windows-Linux-macOS-%E5%B9%B3%E5%8F%B0"><span class="nav-number">1.2.1.</span> <span class="nav-text">1. Windows, Linux, macOS 平台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Android-%E5%B9%B3%E5%8F%B0-Termux"><span class="nav-number">1.2.2.</span> <span class="nav-text">2. Android 平台 (Termux)**</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%EF%BC%9A%E4%BD%BF%E7%94%A8-DeepSeek-R1-%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.3.</span> <span class="nav-text">第三部分：使用 DeepSeek-R1 模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%EF%BC%9A%E9%92%88%E5%AF%B9%E4%BD%8E%E9%85%8D%E7%BD%AE%E8%AE%BE%E5%A4%87%E7%9A%84%E4%BC%98%E5%8C%96-DeepSeek-R1-Distill-Qwen-1-5B"><span class="nav-number">1.4.</span> <span class="nav-text">第四部分：针对低配置设备的优化 (DeepSeek-R1-Distill-Qwen-1.5B)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%EF%BC%9A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94"><span class="nav-number">1.5.</span> <span class="nav-text">第五部分：常见问题解答</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">2.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="PW0N"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">PW0N</p>
  <div class="site-description" itemprop="description">阅读我对网络技术的深入分析和最新趋势的见解，同时了解我个人的生活记录和经验分享。
无论是技术教程还是生活故事，都能在这里找到有趣的内容。
</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">64</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Duoqixiaozei" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Duoqixiaozei" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:pw0nxx@163.com" title="E-Mail → mailto:pw0nxx@163.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2024 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PW0N</span>
</div>
由 <a  class="theme-link"  target="_blank" rel="noopener external nofollow noreferrer" href="http://hexo.io">Hexo</a> 强力驱动

<a class="theme-link" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/iissnan/hexo-theme-next">


        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>













  

  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'https://www.pw0n.xyz/deploy-deepseek/',]
      });
      });
  </script>

  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script>
  <script>
      pbOptions = {};
        pbOptions.iconStyle = "box";
        pbOptions.boxForm = "horizontal";
        pbOptions.position = "bottomCenter";
        pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      new needShareButton('#needsharebutton-postbottom', pbOptions);
  </script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'Ov23licQslcmqpdOl1SO',
      clientSecret: '82092c2fbc2d05ab92d329b16a599e70451e13b2',
      repo        : 'duoqixiaozei.github.io',
      owner       : 'duoqixiaozei',
      admin       : ['duoqixiaozei'],
      id          : '3ee284cb1ebc75ccd11267233109e18d',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>


        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z\d\-\.\+]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(t.test(e.href)||r.test(e.href))&&(e.href=a.dataset.original)})});</script><script>(r=>{r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,o=r.imageLazyLoadSetting.preloadRatio||1,d=i();function i(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=i());for(var e,n=0;n<d.length;n++)0<=(e=(e=d[n]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*o||document.documentElement.clientHeight*o)&&(()=>{var t,e,a,o,i=d[n];e=function(){d=d.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,o=t.getAttribute("data-original"),a.onload=function(){t.src=o,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=o},t.src!==o&&(a.src=o)))})()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)})(this);</script></body>
</html>
